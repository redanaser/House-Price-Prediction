{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19150bc6",
   "metadata": {
    "id": "19150bc6"
   },
   "source": [
    "# PipeLine and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfe2273e",
   "metadata": {
    "id": "cfe2273e"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "\n",
    "        df = df.drop(columns=['Id', 'GarageConstructionYear', 'SaleMonth', 'FenceQuality', 'AdditionalFeatureValue', 'AdditionalFeature'])\n",
    "\n",
    "        building_category_mapping = {60: 'A', 20: 'B', 70: 'C', 50: 'D', 190: 'E', 45: 'F', 90: 'G',\n",
    "                                     120: 'H', 30: 'I', 85: 'J', 80: 'K', 160: 'L', 75: 'M', 180: 'N', 40: 'O'}\n",
    "        df['BuildingCategory'] = df['BuildingCategory'].map(building_category_mapping)\n",
    "\n",
    "        median_street_length = df.groupby('District')['StreetLineLength'].transform('median')\n",
    "        df['StreetLineLength'] = df['StreetLineLength'].fillna(median_street_length)\n",
    "        df['AlleyAccessType'] = df['AlleyAccessType'].fillna('None').astype('category')\n",
    "        df['MasonrySize'] = df['MasonrySize'].fillna(0)\n",
    "        df['MasonryType'] = np.where(df['MasonrySize'] == 0, 'Na', df['MasonryType'])\n",
    "\n",
    "        basement_cols = ['BasementHeight', 'BasementCondition', 'BasementAccess', 'BasementFinish1',\n",
    "                         'BasementFinishedArea1', 'BasementFinish2', 'BasementFinishedArea2', 'BasementUnfinishedArea']\n",
    "        df.loc[df['TotalBasementArea'] == 0, basement_cols] = df.loc[df['TotalBasementArea'] == 0, basement_cols].fillna(\n",
    "            {'BasementHeight': 'Na', 'BasementCondition': 'Na', 'BasementAccess': 'Na', 'BasementFinish1': 'Na',\n",
    "             'BasementFinishedArea1': 0, 'BasementFinish2': 'Na', 'BasementFinishedArea2': 0, 'BasementUnfinishedArea': 0})\n",
    "\n",
    "        garage_cols = ['GarageInterior', 'GarageLocation', 'GarageQuality', 'GarageCondition']\n",
    "        df.loc[df['GarageSize'] == 0, garage_cols] = df.loc[df['GarageSize'] == 0, garage_cols].fillna(\n",
    "            {'GarageInterior': 'Na', 'GarageLocation': 'Na', 'GarageQuality': 'Na', 'GarageCondition': 'Na'})\n",
    "\n",
    "        df['PoolQuality'] = np.where(df['PoolSize'] == 0, 'Na', df['PoolQuality'])\n",
    "        df['FireplaceQuality'] = np.where(df['FireplaceCount'] == 0, 'Na', df['FireplaceQuality'])\n",
    "    \n",
    "\n",
    "        df['TotalBasementBathrooms'] = df['BasementFullBathrooms'] + df['BasementHalfBathrooms']\n",
    "        df = df.drop(columns=['BasementFullBathrooms', 'BasementHalfBathrooms'])\n",
    "\n",
    "        df['TotalBathrooms'] = df['FullBathrooms'] + df['HalfBathrooms']\n",
    "        df = df.drop(columns=['FullBathrooms', 'HalfBathrooms'])\n",
    "\n",
    "        df['PropertyAge'] = df['SaleYear'] - df['ConstructionYear']\n",
    "        df['RenovationTime'] = df['SaleYear'] - df['RenovationYear']\n",
    "        df = df.drop(columns=['SaleYear', 'ConstructionYear', 'RenovationYear'])\n",
    "\n",
    "        return df\n",
    "\n",
    "categorical_features = [\n",
    "    'BuildingCategory', 'ZoningClassification', 'RoadAccessType', 'AlleyAccessType', 'ParcelShape',\n",
    "    'TerrainFlatness', 'UtilityAvailability', 'ParcelSettings', 'District', 'RoadProximity1',\n",
    "    'RoadProximity2', 'DwellingType', 'DwellingStyle', 'RoofType', 'RoofMaterial', 'ExteriorCladding1',\n",
    "    'ExteriorCladding2', 'MasonryType', 'ExteriorQuality', 'ExteriorCondition', 'FoundationType',\n",
    "    'BasementHeight', 'BasementCondition', 'BasementAccess', 'BasementFinish1', 'BasementFinish2',\n",
    "    'HeatingType', 'HeatingQuality', 'AirConditioning', 'ElectricalSystem', 'KitchenQuality',\n",
    "    'FunctionalityRating', 'FireplaceQuality', 'GarageLocation', 'GarageInterior', 'GarageQuality',\n",
    "    'GarageCondition', 'DrivewayType', 'PoolQuality', 'SaleType', 'SaleCondition'\n",
    "]\n",
    "ordinal_columns = [\n",
    "    'TerrainSlope', 'KitchenQuality', 'ExteriorQuality', 'HeatingQuality',\n",
    "    'FunctionalityRating', 'FireplaceQuality', 'ExteriorCondition',\n",
    "    'BasementHeight', 'BasementCondition', 'GarageQuality', 'GarageCondition',\n",
    "    'PoolQuality'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'StreetLineLength', 'ParcelSize', 'MaterialQuality', 'ConditionRating', 'RenovationTime',\n",
    "    'MasonrySize', 'BasementFinishedArea1', 'BasementFinishedArea2', 'BasementUnfinishedArea',\n",
    "    'TotalBasementArea', 'GroundFloorArea', 'UpperFloorArea', 'LowQualityArea', 'LivingArea',\n",
    "    'TotalBasementBathrooms', 'TotalBathrooms', 'BedroomAbvGr', 'KitchenAbvGr', 'TotalRooms',\n",
    "    'FireplaceCount', 'GarageCapacity', 'GarageSize', 'WoodDeckArea', 'OpenPorchArea', 'EnclosedPorchArea',\n",
    "    'ThreeSeasonPorchArea', 'ScreenPorchArea', 'PoolSize', 'PropertyAge'\n",
    "]\n",
    "\n",
    "ordinal_mapping = {\n",
    "    'TerrainSlope': ['Sev', 'Mod', 'Gtl'],\n",
    "    'KitchenQuality': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExteriorQuality': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'HeatingQuality': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'FunctionalityRating': ['Sev', 'Maj2', 'Maj1', 'Mod', 'Min1', 'Min2', 'Typ'],\n",
    "    'FireplaceQuality': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExteriorCondition': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BasementHeight': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BasementCondition': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageQuality': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCondition': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PoolQuality': ['Na', 'Fa', 'Gd', 'Ex'],\n",
    "}\n",
    "\n",
    "\n",
    "# Create imputers for categorical and numerical columns\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Create pipelines for each type of feature\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', numerical_imputer),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', categorical_imputer),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', categorical_imputer),\n",
    "    ('encoder', OrdinalEncoder(categories=[ordinal_mapping[col] for col in ordinal_columns]))\n",
    "])\n",
    "\n",
    "# ColumnTransformer to apply the transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, [col for col in categorical_features if col not in ordinal_columns]),\n",
    "        ('ord', ordinal_pipeline, ordinal_columns)\n",
    "    ])\n",
    "\n",
    "# Full pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('custom', CustomTransformer()),\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc56c4c0",
   "metadata": {
    "id": "cc56c4c0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = df.drop('OutcomeVariable', axis=1)\n",
    "y = df['OutcomeVariable'].copy()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Process train and test sets separately\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "033670ec",
   "metadata": {
    "id": "033670ec"
   },
   "outputs": [],
   "source": [
    "X_processed = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809570a7",
   "metadata": {
    "id": "809570a7"
   },
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9de9d3f5",
   "metadata": {
    "id": "9de9d3f5",
    "outputId": "f310b678-a4a4-49e6-eed1-f60ba141a0f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model R2 Score: 0.8837259211174341\n",
      "Base Model RMSE Score: 29864.027097320424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Linear Regression\n",
    "base_model = LinearRegression()\n",
    "base_model.fit(X_train_processed, y_train)\n",
    "y_pred_base = base_model.predict(X_test_processed)\n",
    "print(\"Base Model R2 Score:\", r2_score(y_test, y_pred_base))\n",
    "print(\"Base Model RMSE Score:\", mean_squared_error(y_test, y_pred_base, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f96eb",
   "metadata": {
    "id": "212f96eb"
   },
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1145456",
   "metadata": {
    "id": "d1145456",
    "outputId": "8ca6c8ce-6978-4108-8a00-97eae4f6a375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge R2 Score: 0.8831355558883749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Train Ridge Regression\n",
    "r = Ridge()\n",
    "r.fit(X_train_processed, y_train)\n",
    "y_pred = r.predict(X_test_processed)\n",
    "current_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Ridge R2 Score:\", current_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f60f4",
   "metadata": {
    "id": "5b6f60f4"
   },
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c82450",
   "metadata": {
    "id": "57c82450",
    "outputId": "f99f9e14-f92e-4970-8159-3aa88406b07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso R2 Score: 0.8831355558883749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:609: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48549645607.29712, tolerance: 696659484.3571945\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Train Lasso Regression\n",
    "l = Lasso()\n",
    "l.fit(X_train_processed, y_train)\n",
    "y_pred = r.predict(X_test_processed)\n",
    "current_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Lasso R2 Score:\", current_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f734ca",
   "metadata": {
    "id": "48f734ca"
   },
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697abaf",
   "metadata": {
    "id": "2697abaf",
    "outputId": "aef2749b-2228-4846-aa29-6910616c0aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 34185.51046095447\n",
      "Random Forest R2 Score: 0.8476402314700777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "tree_reg = DecisionTreeRegressor(random_state= 42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "tree_reg.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predict the target variable on the test set\n",
    "y_pred = tree_reg.predict(X_test_processed)\n",
    "\n",
    "# Compute RMSE and R2 scores\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest RMSE:\", rmse)\n",
    "print(\"Random Forest R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045ef4c",
   "metadata": {
    "id": "4045ef4c"
   },
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e57a5",
   "metadata": {
    "id": "012e57a5",
    "outputId": "d9330601-80a7-404e-c255-3f358e56eeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 28311.93151457296\n",
      "Random Forest R2 Score: 0.8954978648320329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "forest_reg.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predict the target variable on the test set\n",
    "y_pred = forest_reg.predict(X_test_processed)\n",
    "\n",
    "# Compute RMSE and R2 scores\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest RMSE:\", rmse)\n",
    "print(\"Random Forest R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa2d56",
   "metadata": {
    "id": "c9fa2d56"
   },
   "source": [
    "## RandomForestRegressor w CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320072e7",
   "metadata": {
    "id": "320072e7",
    "outputId": "455991d4-e8bf-471a-d469-ed61960a67db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R-squared scores: [0.86403803 0.89211303 0.92036809 0.77215807 0.88166662 0.88707923\n",
      " 0.88732046 0.88372802 0.80909046 0.85875455]\n",
      "Mean R-squared: 0.865631656695653\n",
      "Standard deviation of R-squared: 0.04146853400660071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation with R-squared scoring\n",
    "forest_scores = cross_val_score(forest_reg, X_processed, y, scoring='r2', cv=10)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Cross-validated R-squared scores:\", forest_scores)\n",
    "print(\"Mean R-squared:\", forest_scores.mean())\n",
    "print(\"Standard deviation of R-squared:\", forest_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435abba4",
   "metadata": {
    "id": "435abba4"
   },
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca19bf8",
   "metadata": {
    "id": "2ca19bf8",
    "outputId": "4b5ef3dc-f49e-4933-8f4d-f1a3577c64ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 35450.152820756455\n",
      "R²: 0.8361590757590672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Parameters provided\n",
    "params = {\n",
    "    'svr__C': 100,\n",
    "    'svr__degree': 2,\n",
    "    'svr__epsilon': 1,\n",
    "    'svr__gamma': 'scale',\n",
    "    'svr__kernel': 'linear'\n",
    "}\n",
    "\n",
    "# Create the SVR model\n",
    "svr = SVR(C=params['svr__C'],\n",
    "          degree=params['svr__degree'],\n",
    "          epsilon=params['svr__epsilon'],\n",
    "          gamma=params['svr__gamma'],\n",
    "          kernel=params['svr__kernel'])\n",
    "\n",
    "# Alternatively, if not using a pipeline, just use the SVR instance directly\n",
    "svr.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svr.predict(X_test_processed)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Calculate R² score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the scores\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a617dba",
   "metadata": {
    "id": "8a617dba"
   },
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101da4c1",
   "metadata": {
    "id": "101da4c1",
    "outputId": "7bfcd3d9-8f9c-42f1-8931-7cac7e996b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model RMSE: 26400.46011609426\n",
      "Best Model R2 Score: 0.9091323790520921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Train Gradient Boosting Regression\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train_processed, y_train)\n",
    "y_pred = model.predict(X_test_processed)\n",
    "current_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE and R2 scores\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Model RMSE:\", rmse)\n",
    "print(\"Best Model R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd1f3e",
   "metadata": {
    "id": "c0fd1f3e"
   },
   "source": [
    "## xgboost with HP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9783967d",
   "metadata": {
    "id": "9783967d",
    "outputId": "d1174eaa-415a-47ec-c579-60a61d0a8e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Model Parameters: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.06170036981151762, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 415, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.7610340282968818, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "Best Model RMSE: 23779.472468768075\n",
      "Best Model R2 Score: 0.9262791052663369\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the search spaces for hyperparameters\n",
    "search_spaces = {\n",
    "    'max_depth': (3, 15),\n",
    "    'n_estimators': (50, 500),\n",
    "    'learning_rate': (0.01, 0.5, 'log-uniform'),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb_reg = XGBRegressor(random_state=42)\n",
    "\n",
    "# Perform Bayesian hyperparameter optimization\n",
    "bayes_search = BayesSearchCV(xgb_reg, search_spaces, n_iter=100, cv=None, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "bayes_search.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get the best model from the search\n",
    "best_xgb_reg = bayes_search.best_estimator_\n",
    "\n",
    "# Predict on the test set using the best model\n",
    "y_pred = best_xgb_reg.predict(X_test_processed)\n",
    "\n",
    "# Compute RMSE and R2 scores\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Model Parameters:\", best_xgb_reg.get_params())\n",
    "print(\"Best Model RMSE:\", rmse)\n",
    "print(\"Best Model R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73710f02",
   "metadata": {
    "id": "73710f02",
    "outputId": "ebf7c085-8cb7-4e0e-f0a7-3868374d4e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model RMSE: 10773.78556777796\n",
      "Best Model R2 Score: 0.981595315287704\n"
     ]
    }
   ],
   "source": [
    "best_params = best_xgb_reg.get_params()\n",
    "new_xgb_reg = XGBRegressor(**best_params)\n",
    "\n",
    "new_xgb_reg.fit(X_processed, y)\n",
    "\n",
    "y_pred = new_xgb_reg.predict(X_processed)\n",
    "\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(\"Best Model RMSE:\", rmse)\n",
    "print(\"Best Model R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "262cd0e0",
   "metadata": {
    "id": "262cd0e0",
    "outputId": "714d6455-84b5-4c97-88a0-b1534008ff9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_best_xgb_reg_bsht_hw.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming best_svr is the best model you want to save\n",
    "joblib.dump(new_xgb_reg, 'final_best_xgb_reg_bsht_hw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e824716f",
   "metadata": {
    "id": "e824716f",
    "outputId": "77a89231-8dfe-4729-f000-19631f4e0f24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_19956\\3804388516.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Model', 'R2', 'Improvement', 'Reason'])\n",
    "\n",
    "# Function to add a row to the DataFrame\n",
    "def add_result(model_name, r2, improvement, reason):\n",
    "    global results  # Ensure we're modifying the global DataFrame\n",
    "    new_row = {\n",
    "        'Model': model_name,\n",
    "        'R2': r2,\n",
    "        'Improvement': improvement,\n",
    "        'Reason': reason\n",
    "    }\n",
    "    results = results.append(new_row, ignore_index=True)\n",
    "\n",
    "# Example usage of the function\n",
    "add_result('LinearRegression', 0.8837, 'No', 'Establishing a baseline with a simple, interpretable model')\n",
    "add_result('Ridge', 0.8831, 'No', 'Evaluating regularization to prevent overfitting in linear models')\n",
    "add_result('Lasso', 0.8831, 'No', 'Testing feature selection capabilities via regularization')\n",
    "add_result('DecisionTreeRegressor', 0.8476, 'No', 'Exploring non-linear relationships with a simple tree model')\n",
    "add_result('RandomForestRegressor', 0.8954, 'Yes', 'Improving performance using ensemble learning with multiple trees')\n",
    "add_result('RandomForestRegressor w CrossVal', 0.8656, 'No', 'a Assessing model stability and performance with cross-validation')\n",
    "add_result('SVR', 0.8361, 'No', 'Investigating the performance of Support Vector Regression for non-linear data')\n",
    "add_result('GradientBoostingRegressor', 0.9091, 'Yes', 'Enhancing prediction accuracy with gradient boosting technique')\n",
    "add_result('xgboost with HP Tuning', 0.9262, 'Yes', 'Optimizing performance with a powerful gradient boosting ensemble method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f610015",
   "metadata": {
    "id": "4f610015",
    "outputId": "d25d1a7e-0ff7-4c84-ca45-de96215cd843"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2</th>\n",
       "      <th>Improvement</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>No</td>\n",
       "      <td>Establishing a baseline with a simple, interpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>No</td>\n",
       "      <td>Evaluating regularization to prevent overfitti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>No</td>\n",
       "      <td>Testing feature selection capabilities via reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>No</td>\n",
       "      <td>Exploring non-linear relationships with a simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Improving performance using ensemble learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor w CrossVal</td>\n",
       "      <td>0.8656</td>\n",
       "      <td>No</td>\n",
       "      <td>a Assessing model stability and performance wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>No</td>\n",
       "      <td>Investigating the performance of Support Vecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Enhancing prediction accuracy with gradient bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost with HP Tuning</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Optimizing performance with a powerful gradien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model      R2 Improvement  \\\n",
       "0                  LinearRegression  0.8837          No   \n",
       "1                             Ridge  0.8831          No   \n",
       "2                             Lasso  0.8831          No   \n",
       "3             DecisionTreeRegressor  0.8476          No   \n",
       "4             RandomForestRegressor  0.8954         Yes   \n",
       "5  RandomForestRegressor w CrossVal  0.8656          No   \n",
       "6                               SVR  0.8361          No   \n",
       "7         GradientBoostingRegressor  0.9091         Yes   \n",
       "8            xgboost with HP Tuning  0.9262         Yes   \n",
       "\n",
       "                                              Reason  \n",
       "0  Establishing a baseline with a simple, interpr...  \n",
       "1  Evaluating regularization to prevent overfitti...  \n",
       "2  Testing feature selection capabilities via reg...  \n",
       "3  Exploring non-linear relationships with a simp...  \n",
       "4  Improving performance using ensemble learning ...  \n",
       "5  a Assessing model stability and performance wi...  \n",
       "6  Investigating the performance of Support Vecto...  \n",
       "7  Enhancing prediction accuracy with gradient bo...  \n",
       "8  Optimizing performance with a powerful gradien...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a4fd1f",
   "metadata": {
    "id": "63a4fd1f"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "858e05a0",
   "metadata": {
    "id": "858e05a0"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8279e8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1461\n",
       "1       1462\n",
       "2       1463\n",
       "3       1464\n",
       "4       1465\n",
       "        ... \n",
       "1454    2915\n",
       "1455    2916\n",
       "1456    2917\n",
       "1457    2918\n",
       "1458    2919\n",
       "Name: Id, Length: 1459, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID=test['Id']\n",
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06b5a73c",
   "metadata": {
    "id": "06b5a73c"
   },
   "outputs": [],
   "source": [
    "X_test_transformed = pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5b28ef2",
   "metadata": {
    "id": "d5b28ef2"
   },
   "outputs": [],
   "source": [
    "test_predictions = new_xgb_reg.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f321a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'ID':ID,'SalePrice':test_predictions}\n",
    "sub=pd.DataFrame(data)\n",
    "sub.to_csv('sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0aa852c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>122618.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>171609.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>179532.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>186192.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>179937.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>80483.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>78083.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>168832.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>126029.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>209093.690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID   SalePrice\n",
       "0     1461  122618.860\n",
       "1     1462  171609.770\n",
       "2     1463  179532.980\n",
       "3     1464  186192.840\n",
       "4     1465  179937.550\n",
       "...    ...         ...\n",
       "1454  2915   80483.200\n",
       "1455  2916   78083.170\n",
       "1456  2917  168832.110\n",
       "1457  2918  126029.195\n",
       "1458  2919  209093.690\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74c7ee",
   "metadata": {},
   "source": [
    "# Finale Pipeline with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d893d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "\n",
    "        df = df.drop(columns=['Id', 'GarageConstructionYear', 'SaleMonth', 'FenceQuality', 'AdditionalFeatureValue', 'AdditionalFeature'])\n",
    "\n",
    "        building_category_mapping = {60: 'A', 20: 'B', 70: 'C', 50: 'D', 190: 'E', 45: 'F', 90: 'G',\n",
    "                                     120: 'H', 30: 'I', 85: 'J', 80: 'K', 160: 'L', 75: 'M', 180: 'N', 40: 'O'}\n",
    "        df['BuildingCategory'] = df['BuildingCategory'].map(building_category_mapping)\n",
    "\n",
    "        median_street_length = df.groupby('District')['StreetLineLength'].transform('median')\n",
    "        df['StreetLineLength'] = df['StreetLineLength'].fillna(median_street_length)\n",
    "        df['AlleyAccessType'] = df['AlleyAccessType'].fillna('None').astype('category')\n",
    "        df['MasonrySize'] = df['MasonrySize'].fillna(0)\n",
    "        df['MasonryType'] = np.where(df['MasonrySize'] == 0, 'Na', df['MasonryType'])\n",
    "\n",
    "        basement_cols = ['BasementHeight', 'BasementCondition', 'BasementAccess', 'BasementFinish1',\n",
    "                         'BasementFinishedArea1', 'BasementFinish2', 'BasementFinishedArea2', 'BasementUnfinishedArea']\n",
    "        df.loc[df['TotalBasementArea'] == 0, basement_cols] = df.loc[df['TotalBasementArea'] == 0, basement_cols].fillna(\n",
    "            {'BasementHeight': 'Na', 'BasementCondition': 'Na', 'BasementAccess': 'Na', 'BasementFinish1': 'Na',\n",
    "             'BasementFinishedArea1': 0, 'BasementFinish2': 'Na', 'BasementFinishedArea2': 0, 'BasementUnfinishedArea': 0})\n",
    "\n",
    "        garage_cols = ['GarageInterior', 'GarageLocation', 'GarageQuality', 'GarageCondition']\n",
    "        df.loc[df['GarageSize'] == 0, garage_cols] = df.loc[df['GarageSize'] == 0, garage_cols].fillna(\n",
    "            {'GarageInterior': 'Na', 'GarageLocation': 'Na', 'GarageQuality': 'Na', 'GarageCondition': 'Na'})\n",
    "\n",
    "        df['PoolQuality'] = np.where(df['PoolSize'] == 0, 'Na', df['PoolQuality'])\n",
    "        df['FireplaceQuality'] = np.where(df['FireplaceCount'] == 0, 'Na', df['FireplaceQuality'])\n",
    "\n",
    "        df['TotalBasementBathrooms'] = df['BasementFullBathrooms'] + df['BasementHalfBathrooms']\n",
    "        df = df.drop(columns=['BasementFullBathrooms', 'BasementHalfBathrooms'])\n",
    "\n",
    "        df['TotalBathrooms'] = df['FullBathrooms'] + df['HalfBathrooms']\n",
    "        df = df.drop(columns=['FullBathrooms', 'HalfBathrooms'])\n",
    "\n",
    "        df['PropertyAge'] = df['SaleYear'] - df['ConstructionYear']\n",
    "        df['RenovationTime'] = df['SaleYear'] - df['RenovationYear']\n",
    "        df = df.drop(columns=['SaleYear', 'ConstructionYear', 'RenovationYear'])\n",
    "\n",
    "        return df\n",
    "\n",
    "categorical_features = [\n",
    "    'BuildingCategory', 'ZoningClassification', 'RoadAccessType', 'AlleyAccessType', 'ParcelShape',\n",
    "    'TerrainFlatness', 'UtilityAvailability', 'ParcelSettings', 'District', 'RoadProximity1',\n",
    "    'RoadProximity2', 'DwellingType', 'DwellingStyle', 'RoofType', 'RoofMaterial', 'ExteriorCladding1',\n",
    "    'ExteriorCladding2', 'MasonryType', 'ExteriorQuality', 'ExteriorCondition', 'FoundationType',\n",
    "    'BasementHeight', 'BasementCondition', 'BasementAccess', 'BasementFinish1', 'BasementFinish2',\n",
    "    'HeatingType', 'HeatingQuality', 'AirConditioning', 'ElectricalSystem', 'KitchenQuality',\n",
    "    'FunctionalityRating', 'FireplaceQuality', 'GarageLocation', 'GarageInterior', 'GarageQuality',\n",
    "    'GarageCondition', 'DrivewayType', 'PoolQuality', 'SaleType', 'SaleCondition'\n",
    "]\n",
    "ordinal_columns = [\n",
    "    'TerrainSlope', 'KitchenQuality', 'ExteriorQuality', 'HeatingQuality',\n",
    "    'FunctionalityRating', 'FireplaceQuality', 'ExteriorCondition',\n",
    "    'BasementHeight', 'BasementCondition', 'GarageQuality', 'GarageCondition',\n",
    "    'PoolQuality'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'StreetLineLength', 'ParcelSize', 'MaterialQuality', 'ConditionRating', 'RenovationTime',\n",
    "    'MasonrySize', 'BasementFinishedArea1', 'BasementFinishedArea2', 'BasementUnfinishedArea',\n",
    "    'TotalBasementArea', 'GroundFloorArea', 'UpperFloorArea', 'LowQualityArea', 'LivingArea',\n",
    "    'TotalBasementBathrooms', 'TotalBathrooms', 'BedroomAbvGr', 'KitchenAbvGr', 'TotalRooms',\n",
    "    'FireplaceCount', 'GarageCapacity', 'GarageSize', 'WoodDeckArea', 'OpenPorchArea', 'EnclosedPorchArea',\n",
    "    'ThreeSeasonPorchArea', 'ScreenPorchArea', 'PoolSize', 'PropertyAge'\n",
    "]\n",
    "\n",
    "ordinal_mapping = {\n",
    "    'TerrainSlope': ['Sev', 'Mod', 'Gtl'],\n",
    "    'KitchenQuality': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExteriorQuality': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'HeatingQuality': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'FunctionalityRating': ['Sev', 'Maj2', 'Maj1', 'Mod', 'Min1', 'Min2', 'Typ'],\n",
    "    'FireplaceQuality': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'ExteriorCondition': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BasementHeight': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'BasementCondition': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageQuality': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'GarageCondition': ['Na', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    'PoolQuality': ['Na', 'Fa', 'Gd', 'Ex'],\n",
    "}\n",
    "\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', numerical_imputer),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', categorical_imputer),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputer', categorical_imputer),\n",
    "    ('encoder', OrdinalEncoder(categories=[ordinal_mapping[col] for col in ordinal_columns]))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, [col for col in categorical_features if col not in ordinal_columns]),\n",
    "        ('ord', ordinal_pipeline, ordinal_columns)\n",
    "    ])\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'random_state': 42\n",
    "}\n",
    "new_xgb_reg = XGBRegressor(**best_params)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('custom', CustomTransformer()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', new_xgb_reg)\n",
    "])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "y_pred = pipeline.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d12e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('trained_hw_pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca6b6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
